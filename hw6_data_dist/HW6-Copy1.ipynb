{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam-Ham Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPORTS :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from matplotlib import pyplot as plt\n",
    "from math import e\n",
    "from math import log\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sys import maxsize\n",
    "from scipy import stats\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA LOADING:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = sio.loadmat(\"letters_data.mat\") #/Users/AhmedThabet/Desktop/school/189/HOMEWORK/HW5/spam_ham/\n",
    "X = data['train_x']\n",
    "# X = np.insert(X, X.shape[1], 1, axis=1)\n",
    "# X = scale(X)\n",
    "y = data['train_y']\n",
    "# y = y.reshape((23702, 1))\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.8, random_state=43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLASSES :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####    NODE :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Neural_Network():\n",
    "    def __init__(self):\n",
    "        self.input_layer = 784\n",
    "        self.hidden_layer = 200\n",
    "        self.output_layer = 26\n",
    "    \n",
    "        self.V = np.random.randn(self.hidden_layer, self.input_layer + 1)\n",
    "        self.W = np.random.randn(self.output_layer, self.hidden_layer + 1)\n",
    "        \n",
    "    def for_pass(self, X): # X.shape = (785, 1)\n",
    "        self.Z1 = np.dot(self.V, X)\n",
    "        self.h = tanh(self.Z1)\n",
    "        self.h = self.h.reshape((1, 200))\n",
    "        _h = np.insert(self.h, self.h.shape[1], 1, axis=1)\n",
    "        _h = _h.reshape((201, 1))\n",
    "        self.Z2 = np.dot(self.W, _h)\n",
    "        Z = softmax(self.Z2)\n",
    "        return np.array(Z)\n",
    "    \n",
    "    def back_pass(self, X, y, i):\n",
    "        self.Z = self.for_pass(X)\n",
    "        Y = 0\n",
    "        errv = 0\n",
    "        for j in range(len(y)):\n",
    "            Y += y[j]\n",
    "            t = \\\n",
    "            np.dot(self.W.T, self.Z) - \\\n",
    "             self.W[j].reshape(len(self.W[j]),1)\n",
    "            errv += y[j] * t\n",
    "            \n",
    "        Y *= -self.Z[i]\n",
    "        errw = -y[i] + Y\n",
    "        errw = self.h * errw\n",
    "        return errw.reshape((errw.shape[1], 1)), errv\n",
    "    \n",
    "    def SGD(self, X, y, _epsislon, num_iterations):\n",
    "        i = 0\n",
    "        W, V = self.W, self.V\n",
    "\n",
    "        points = [pt for pt in X]\n",
    "        classes = [cls for cls in y]\n",
    "        up = len(points) // 50\n",
    "        for j in range(num_iterations):\n",
    "            x = X[j]\n",
    "            y_t = y[j]\n",
    "            y_t = [0 if i != y_t else 1 for i in range(26)]\n",
    "            x = np.array(x)\n",
    "            y_t = np.array(y_t)\n",
    "            \n",
    "            errw, errv = self.back_pass(x, y_t, j)\n",
    "\n",
    "            correctionW = (_epsislon*errw)\n",
    "            correctionV = (_epsislon*errv)\n",
    "            W += correctionW \n",
    "            V += correctionV\n",
    "        self.V = V\n",
    "        self.W = W\n",
    "        return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 201)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X = np.array([[1,0],[1,1],[0,0]])\n",
    "N = Neural_Network()\n",
    "# N.SGD(X, y, 10**-5, 1)\n",
    "# Z = N.for_pass(X[1090].reshape((785,1)))\n",
    "# y = np.array([[0,1,1]])\n",
    "errw, errv = N.back_pass(X[1090], y_t, 2)\n",
    "# print(\"Err_V = \\n\", errv)#.reshape(len(errv),1))\n",
    "# print(\"Err_W = \\n\", errw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####    COST FUNCTION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def dtanh(x):\n",
    "    return 1.0 - np.tanh(x)**2\n",
    "\n",
    "def L(Z, y):\n",
    "    return y[i] * np.log(Z[i])\n",
    "\n",
    "def J(h, y):\n",
    "    sum = 0\n",
    "    for i in range(len(h)):\n",
    "        sum += L(h[i], y[i])\n",
    "    return sum\n",
    "\n",
    "def softmax(x):\n",
    "#     return _softmax(np.exp(x) / np.sum(np.exp(x), axis=0))\n",
    "    z = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "#     print(z)\n",
    "    return z\n",
    "\n",
    "\n",
    "def _softmax(x):\n",
    "    if len(x.shape) > 1:\n",
    "        p = []\n",
    "        for lst in x:\n",
    "            p.append(lst.tolist().index(max(lst)))\n",
    "        return p\n",
    "    else:\n",
    "        return x.tolist().index(max(x))\n",
    "\n",
    "        \n",
    "# class Neural_Network():\n",
    "#     def __init__(self):\n",
    "#         self.input_layer = 2\n",
    "#         self.hidden_layer = 1\n",
    "#         self.output_layer = 3\n",
    "    \n",
    "#         self.V = np.random.randn(self.input_layer, self.hidden_layer)\n",
    "#         self.W = np.random.randn(self.hidden_layer, self.output_layer)\n",
    "#     def for_pass(self, X):\n",
    "#         self.Z1 = np.dot(X, self.V)#np.dot(self.V, X)\n",
    "#         self.h = tanh(self.Z1)\n",
    "#         self.Z2 = np.dot(self.h, self.W)\n",
    "#         print(self.Z2)\n",
    "#         Z = softmax(self.Z2)\n",
    "#         return np.array(Z)\n",
    "#     def back_pass(self, X, y, i):\n",
    "#         self.Z = self.for_pass(X)\n",
    "#         yj = 0\n",
    "#         errv = 0\n",
    "#         for j in range(len(y)):\n",
    "#             yj += y[j] \n",
    "#             t = \\\n",
    "#             (np.dot(self.W, self.Z.reshape((len(self.Z), 1))) - self.W[j])\n",
    "# #             t = t.reshape((len(t), 1))\n",
    "#             errv += y[j] * t\n",
    "            \n",
    "#         yj *= -self.Z[i] \n",
    "#         errw = float(-y[0][i] + self.Z[i])\n",
    "#         errw *= self.h\n",
    "#         return errw, errv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GD(X, y, _epsislon, _lambda, num_iterations):\n",
    "    w = np.zeros((13,1))\n",
    "    old_val = w\n",
    "    same = []\n",
    "    i = 0\n",
    "    while i < num_iterations:\n",
    "        dt_p = np.dot(X, w)\n",
    "        correction = np.dot((X.T), (y - sigmoid(dt_p)))\n",
    "        correction = (_epsislon/(i+1))*correction + 2*_lambda*w\n",
    "        w += correction \n",
    "        i+=1\n",
    "    return w\n",
    "\n",
    "\n",
    "def SGD(X, y, _epsislon, _lambda, num_iterations, W, V):\n",
    "    i = 0\n",
    "    old_val = w\n",
    "    same = []\n",
    "    points = [pt for pt in X]\n",
    "    classes = [cls for cls in y]\n",
    "    up = len(points) // 50\n",
    "    for j in range(up):\n",
    "        x = X[:(up // 2)]\n",
    "        y = y[:(up // 2)]\n",
    "        x = np.array(x)\n",
    "        y = np.array(y)\n",
    "        while i < num_iterations:\n",
    "            dt_p = np.dot(x, w)\n",
    "            correction = np.dot(x.T, (y - sigmoid(dt_p)))\n",
    "            correction = (_epsislon*correction + 2*_lambda*w)\n",
    "            w += correction \n",
    "            i+=1\n",
    "    return w\n",
    "\n",
    "def SGD(X, y, _epsislon, num_iterations, W, V):\n",
    "    i = 0\n",
    "    old_val = w\n",
    "    same = []\n",
    "    points = [pt for pt in X]\n",
    "    classes = [cls for cls in y]\n",
    "    up = len(points) // 50\n",
    "    for j in range(up):\n",
    "        x = X[j]\n",
    "        y = y[j]\n",
    "        y_t = [0 if i != y else 1 for i in range(26)]\n",
    "        \n",
    "        x = np.array(x)\n",
    "        y = np.array(y_t)\n",
    "        while i < num_iterations:\n",
    "            Z = self.for_pass(X[1090].reshape((785,1)))\n",
    "            errw, errv = self.back_pass(X[1090], y_t, 2)\n",
    "\n",
    "            correction = (_epsislon*correction)\n",
    "            w += correction \n",
    "            i+=1\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RANDOM FOREST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, size=40, max_depth = 30, trees=[]):\n",
    "        self.size = size\n",
    "        self.max_depth = max_depth\n",
    "        self.trees = []\n",
    "    \n",
    "    def train(self, data, labels):\n",
    "        trees = []\n",
    "        for i in range(self.size):\n",
    "            sub_S = []\n",
    "            sub_L = []\n",
    "            for i in np.random.choice(len(labels), len(labels)):\n",
    "                sub_S.append(data[i])\n",
    "                sub_L.append(labels[i])\n",
    "            sub_S = np.array(sub_S)\n",
    "            sub_L = np.array(sub_L)\n",
    "            clf = DecisionTree(max_depth=self.max_depth, from_tree = True)\n",
    "            clf.train(sub_S, sub_L)\n",
    "            self.trees.append(clf)\n",
    "    def predict(self, X):\n",
    "        p = []\n",
    "        for t in self.trees:\n",
    "            p.append(t.predict(X))\n",
    "        p = np.array(p)\n",
    "        if p.ndim == 1:\n",
    "            p = p.reshape((len(p), 1))\n",
    "        best = []\n",
    "        for i in range(p.shape[1]):\n",
    "            best.append(stats.mode(p[:,i])[0][0])\n",
    "        return best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####    HELPER FUNCTIONS: [Data Pre-Processing / cost functions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_labels(X, f):\n",
    "    l = []\n",
    "    for i in X:\n",
    "        if i in l:\n",
    "            continue\n",
    "        if i == f:\n",
    "            l.append(i)\n",
    "    if l != []:\n",
    "        return l\n",
    "\n",
    "def get_features(X, _all):\n",
    "    l = [0 for i in range(len(_all))]\n",
    "    m = dict(zip(_all, l))\n",
    "    for lbl in _all:\n",
    "        o = get_labels(X, lbl)\n",
    "        if o == None:\n",
    "            continue\n",
    "        m[lbl] = o\n",
    "    return m\n",
    "\n",
    "log_2 = lambda x: float(log(x)) / log(2)\n",
    "\n",
    "def entropy(S, labels):\n",
    "    var = 0\n",
    "    Pc = []\n",
    "    j = 0\n",
    "    if len(S) == 0:\n",
    "        return 0\n",
    "    for i in S:\n",
    "        if labels[i] == 0:\n",
    "            Pc.append(i)\n",
    "    Pc = float(len(Pc)) / len(S)\n",
    "    if Pc == 0:\n",
    "        return 0\n",
    "    lg = log_2(Pc)\n",
    "    var -= Pc*lg\n",
    "\n",
    "    Pd = 1 - Pc\n",
    "    if Pd == 0:\n",
    "        return 0\n",
    "    lg = log_2(Pd)\n",
    "    var -= Pd*lg\n",
    "    return (var)\n",
    "\n",
    "def weighted_av_entr(Sl, Sr, labels):\n",
    "    H_Sl = entropy(Sl, labels)\n",
    "    H_Sr = entropy(Sr, labels)\n",
    "    top = len(Sl) * H_Sl + len(Sr) * H_Sr\n",
    "    down = len(Sl) + len(Sr)\n",
    "    return top / down\n",
    "\n",
    "\n",
    "def mode(l):\n",
    "    z = 0\n",
    "    o = 0\n",
    "    for i in l:\n",
    "        if i == 0:\n",
    "            z+=1\n",
    "        else:\n",
    "            o+=1\n",
    "    if z > 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def man_entropy(x,o):\n",
    "    var = 0\n",
    "    if (x + o) == 0:\n",
    "        return - 1\n",
    "    Pc = float(x) / (x+o)\n",
    "    if Pc == 0:\n",
    "        return 0\n",
    "    lg = log_2(Pc)\n",
    "    var -= Pc*lg\n",
    "\n",
    "    Pd = 1 - Pc\n",
    "    if Pd == 0:\n",
    "        return 0\n",
    "    lg = log_2(Pd)\n",
    "    var -= Pd*lg\n",
    "    return var\n",
    "\n",
    "def man_weighted_av_entr(__x,__o, _x, _o):\n",
    "    H_Sl = man_entropy(__x, __o)\n",
    "    H_Sr = man_entropy(_x, _o)\n",
    "    top = (__x+__o) * H_Sl + (_x+_o) * H_Sr\n",
    "    down = (__x+__o) + (_x+_o)\n",
    "    return float(top) / down\n",
    "\n",
    "def _get_features(X):\n",
    "    l = []\n",
    "    for i in X:\n",
    "        if i in l:\n",
    "            continue\n",
    "        else:\n",
    "            l.append(i)\n",
    "    r = [[] for i in range(len(l))]\n",
    "    m = dict(zip(l, r))\n",
    "    return m\n",
    "\n",
    "from operator import itemgetter\n",
    "def max_val(l, i): # assuming this shit works\n",
    "    return max(enumerate(map(itemgetter(i), l)),key=itemgetter(1))\n",
    "\n",
    "def all_done(y):\n",
    "    s = sum(y)\n",
    "    if s == len(y):\n",
    "        return (True, 1)\n",
    "    if s == 0:\n",
    "        return (True, 0)\n",
    "    return (False, \"fuck\")\n",
    "\n",
    "\n",
    "\n",
    "def impurity(left_label_hist, right_label_hist, labels):\n",
    "    classes  = [0,1]\n",
    "    return weighted_av_entr(left_label_hist, right_label_hist, labels)\n",
    "\n",
    "\n",
    "def test_clf(pred, orig):\n",
    "    m = []\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i] == orig[i]:\n",
    "            m.append(1)\n",
    "    res = len(m)/len(pred)\n",
    "    if res > 0.72:\n",
    "        print(\"SUCESS!!!\")\n",
    "    else:\n",
    "        print(\"Failure....\")\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TESTING: {DECISION TREE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.64      0.74      5794\n",
      "          1       0.73      0.91      0.81      6057\n",
      "\n",
      "avg / total       0.80      0.78      0.78     11851\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTree()\n",
    "clf.train(X, y)\n",
    "print(classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TESTING: {RANDOM FOREST}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.88      0.83      5794\n",
      "          1       0.87      0.78      0.82      6057\n",
      "\n",
      "avg / total       0.83      0.83      0.83     11851\n",
      "\n",
      "SUCESS!!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8292127246645853"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForest()\n",
    "clf.train(X, y)\n",
    "print(classification_report(y_test, clf.predict(X_test)))\n",
    "test_clf(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DECISION-TREE:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TRAINING:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.84      0.81     11629\n",
      "          1       0.83      0.77      0.80     12073\n",
      "\n",
      "avg / total       0.81      0.80      0.80     23702\n",
      "\n",
      "SUCESS!!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8045312631845414"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTree(max_depth=20)\n",
    "clf.train(X, y)\n",
    "print(classification_report(y, clf.predict(X)))\n",
    "test_clf(y, clf.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### VALIDATION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.83      0.78      5794\n",
      "          1       0.82      0.72      0.77      6057\n",
      "\n",
      "avg / total       0.78      0.77      0.77     11851\n",
      "\n",
      "SUCESS!!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7748713188760442"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTree()\n",
    "clf.train(X_train, y_train)\n",
    "print(classification_report(y_test, clf.predict(X_test)))\n",
    "test_clf(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RANDOM-FOREST:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TRAINING:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.88      0.82     11629\n",
      "          1       0.87      0.73      0.79     12073\n",
      "\n",
      "avg / total       0.81      0.81      0.80     23702\n",
      "\n",
      "SUCESS!!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.805881360222766"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForest(size=35,max_depth=12)\n",
    "clf.train(X, y)\n",
    "print(classification_report(y, clf.predict(X)))\n",
    "test_clf(y, clf.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### VALIDATION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.86      0.80      5794\n",
      "          1       0.85      0.72      0.78      6057\n",
      "\n",
      "avg / total       0.80      0.79      0.79     11851\n",
      "\n",
      "SUCESS!!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7881191460636233"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForest(size=35,max_depth=12)\n",
    "clf.train(X_train, y_train)\n",
    "print(classification_report(y_test, clf.predict(X_test)))\n",
    "test_clf(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q.5\n",
    "#### VISUALIZING:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "point:  [  0.   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  13.\n",
      "   0.   2.   0.   1.   0.   0.   0.]\n",
      "label: 0\n",
      "TREE: \n",
      "feat =  28  ,  split_val =  1.0\n",
      "LEFT\n",
      "feat =  29  ,  split_val =  1.0\n",
      "RIGHT\n",
      "feat =  3  ,  split_val =  1.0\n",
      "LEFT\n",
      "feat =  9  ,  split_val =  1.0\n",
      "LEFT\n",
      "prediction:  0.0\n"
     ]
    }
   ],
   "source": [
    "l = X_test[101]\n",
    "print(\"point: \", l)\n",
    "print(\"label:\", y_test[101][0])\n",
    "print(\"TREE: \")\n",
    "print(\"prediction: \", clf.predict(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124800, 784)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(785,)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = np.array([[0,0,0],[1,1,1],[2,2,2]])\n",
    "V[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(785,)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.random.randn(1000, 784)\n",
    "X = np.insert(X, X.shape[1], 1, axis=1)\n",
    "y = np.random.randn(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# clf = MLPClassifier(hidden_layer_sizes=(1000, 400), activation='tanh', warm_start=True)\n",
    "clf = MLPClassifier(activation='logistic', solver = 'sgd', learning_rate='adaptive')\n",
    "st = time.clock()\n",
    "clf.fit(X_train, y_train.reshape((len(y_train))))\n",
    "end = time.clock()\n",
    "print(int((-st + end)//60), \"+\", (((-st + end)/60)%1)*60)\n",
    "test_clf(y_test, clf.predict(X_test))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.alpha = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failure....\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.03842147435897436"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_clf(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tst = data['test_x']\n",
    "tst = np.insert(tst, tst.shape[1], 1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pred = []\n",
    "# s = []\n",
    "# pred = clf.predict(tst)\n",
    "import pandas as pd\n",
    "pp = pd.DataFrame({'Category': pred})\n",
    "pp.index += 1\n",
    "pp.to_csv('sub2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# clf = MLPClassifier(hidden_layer_sizes=(1000, 400), activation='tanh', warm_start=True)\n",
    "clf = MLPClassifier(hidden_layer_sizes=(2000),activation='logistic', solver = 'sgd', learning_rate='adaptive', warm_start=True)\n",
    "st = time.clock()\n",
    "clf.fit(X_train, y_train.reshape((len(y_train))))\n",
    "end = time.clock()\n",
    "print(int((-st + end)//60), \"+\", (((-st + end)/60)%1)*60)\n",
    "test_clf(y_test, clf.predict(X_test))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-bdfe02100b44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC()\n",
    "st = time.clock()\n",
    "clf.fit(X_train, y_train.reshape((len(y_train))))\n",
    "end = time.clock()\n",
    "print(int((-st + end)//60), \"+\", (((-st + end)/60)%1)*60)\n",
    "test_clf(y_test, clf.predict(X_test))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convolutional Layer 1.\n",
    "filter_size1 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters1 = 16         # There are 16 of these filters.\n",
    "\n",
    "# Convolutional Layer 2.\n",
    "filter_size2 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters2 = 36         # There are 36 of these filters.\n",
    "\n",
    "# Fully-connected layer.\n",
    "fc_size = 128  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
